#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Beacon ë°ì´í„° (B1~B5, Zone)ì— ëŒ€í•´
- pos_0 ~ pos_4 5-fold ë¶„í•  (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
- train/testë§Œ ì‚¬ìš© (val ì—†ìŒ)
- window_size/step_size ê¸°ë°˜ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° (ê¸°ì¡´ê³¼ ë™ì¼)
ì„ ìœ ì§€í•˜ë©´ì„œ

STraTS supervised í•™ìŠµì— ë§ëŠ” í¬ë§·ìœ¼ë¡œ ì „ì²˜ë¦¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.

ë˜í•œ, ë³€í™˜ ê³¼ì •ì„ ë³´ê¸° ìœ„í•´ ë‹¤ìŒ ì¤‘ê°„ ê²°ê³¼ë¥¼ ëª¨ë‘ ì €ì¥í•œë‹¤.

1) step1_raw   : pos split ì´í›„ train/test raw CSV
2) step2_norm  : ë¹„ì»¨ë³„ z-score ì •ê·œí™”ëœ train/test CSV
3) step3_windows: ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì ìš© í›„ (window_size, 5+1) npz
4) ìµœì¢… STraTS .pt: (times, features, values, label) ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
"""

import os
from glob import glob
from typing import List, Dict, Any

import numpy as np
import pandas as pd
from tqdm import tqdm
import torch


# ğŸ”¹ Split ì´ë¦„ (ê¸°ì¡´ê³¼ ë™ì¼)
split_names = ['pos_0', 'pos_1', 'pos_2', 'pos_3', 'pos_4']

# ğŸ”¹ ë°ì´í„° í´ë” (CSVê°€ ìˆëŠ” ê³³)
base_dirs = ['../../../Git/data/in-motion']

# ğŸ”¹ RSSI í”¼ì²˜
beacon_cols = ['B1', 'B2', 'B3', 'B4', 'B5']

# ğŸ”¹ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
window_size = 10
step_size = 1

# ğŸ”¹ STraTSìš© ì „ì²˜ë¦¬ ì„¤ì •
min_events_per_sample = 5  # í•œ ìƒ˜í”Œ(ìœˆë„ìš°) ì•ˆì— ì´ë²¤íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ë²„ë¦¼

# ğŸ”¹ ì €ì¥ ë£¨íŠ¸
#   - step1_raw, step2_norm, step3_windows, ìµœì¢… .pt ëª¨ë‘ ì´ ì•„ë˜ì— ì €ì¥
save_root_strats = './data_split_beacon_strats'


def compute_beacon_norm_stats(df_all_train: pd.DataFrame,
                              beacon_cols: List[str]) -> Dict[int, Dict[str, float]]:
    """
    train ì „ì²´ì—ì„œ ë¹„ì»¨ë³„ mean/stdë¥¼ ê³„ì‚° (0ì€ ê²°ì¸¡ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ì œì™¸).
    ë°˜í™˜: {feature_id(int): {"mean": float, "std": float}}
    """
    stats: Dict[int, Dict[str, float]] = {}
    for f_idx, col in enumerate(beacon_cols):
        vals = df_all_train[col].replace(0, np.nan).dropna()
        if len(vals) == 0:
            mean = 0.0
            std = 1.0
        else:
            mean = float(vals.mean())
            std = float(vals.std())
            if std == 0 or np.isnan(std):
                std = 1.0
        stats[f_idx] = {"mean": mean, "std": std}
    return stats


def normalize_beacons(df: pd.DataFrame,
                      beacon_cols: List[str],
                      stats: Dict[int, Dict[str, float]]) -> pd.DataFrame:
    """
    ë¹„ì»¨ë³„ z-score ì •ê·œí™”.
    - RSSI == 0 ì€ "ê²°ì¸¡"ìœ¼ë¡œ ê°„ì£¼ â†’ ê·¸ëŒ€ë¡œ 0 ìœ ì§€
    """
    df_norm = df.copy()
    for f_idx, col in enumerate(beacon_cols):
        mean = stats[f_idx]["mean"]
        std = stats[f_idx]["std"]

        def _norm(x):
            if x == 0:
                return 0.0
            return (x - mean) / std

        df_norm[col] = df_norm[col].apply(_norm)
    return df_norm


def window_to_strats_sample(window_values: np.ndarray,
                            zone_label: int,
                            beacon_cols: List[str]) -> Any:
    """
    (window_size, num_beacons) ë°°ì—´ì„
    STraTSìš© (times, features, values, label) ìƒ˜í”Œë¡œ ë³€í™˜.

    - time: 0 ~ window_size-1
    - feature: 0~4 (B1~B5)
    - values: ì •ê·œí™”ëœ RSSI (0ì€ ê²°ì¸¡ â†’ ì´ë²¤íŠ¸ì—ì„œ ì œì™¸)

    ë°˜í™˜: sample dict ë˜ëŠ” None (ì´ë²¤íŠ¸ ê°œìˆ˜ê°€ ë„ˆë¬´ ì ì„ ë•Œ)
    """
    T, F = window_values.shape
    assert F == len(beacon_cols)

    times_list = []
    feat_list = []
    val_list = []

    for t in range(T):
        for f_idx in range(F):
            v = float(window_values[t, f_idx])
            if v == 0.0:
                continue  # ê²°ì¸¡ì€ ì´ë²¤íŠ¸ë¡œ ì“°ì§€ ì•ŠìŒ
            times_list.append(float(t))    # ë‹¨ìœ„ time step
            feat_list.append(int(f_idx))   # beacon index
            val_list.append(v)

    if len(times_list) < min_events_per_sample:
        return None

    sample = {
        "times": np.asarray(times_list, dtype=np.float32),
        "features": np.asarray(feat_list, dtype=np.int32),
        "values": np.asarray(val_list, dtype=np.float32),
        "label": int(zone_label)
    }
    return sample


def main():
    for base_dir in base_dirs:
        folder_name = os.path.basename(base_dir.rstrip('/'))
        csv_files = sorted(glob(os.path.join(base_dir, "*.csv")))

        for split_idx, split_name in enumerate(split_names):
            # ============================================================
            # 1) ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ train/test ë¶„í•  + step1_raw ì €ì¥
            # ============================================================
            all_train_parts: List[pd.DataFrame] = []
            file_split_info: Dict[str, Dict[str, pd.DataFrame]] = {}

            # step1_raw ì €ì¥ í´ë”
            raw_root = os.path.join(save_root_strats, 'step1_raw', folder_name, split_name)
            raw_train_dir = os.path.join(raw_root, 'train')
            raw_test_dir = os.path.join(raw_root, 'test')
            os.makedirs(raw_train_dir, exist_ok=True)
            os.makedirs(raw_test_dir, exist_ok=True)

            for csv_path in csv_files:
                filename = os.path.basename(csv_path)
                base_name = filename.replace('.csv', '')
                df = pd.read_csv(csv_path)
                total_len = len(df)

                if total_len < 5:
                    print(f"âš ï¸ Too short: {filename} (len={total_len})")
                    continue

                # 5ë“±ë¶„ ì¸ë±ìŠ¤
                split_size = total_len // 5
                split_indices = [i * split_size for i in range(5)] + [total_len]

                # í˜„ì¬ splitì„ test ë¶€ë¶„ìœ¼ë¡œ ì‚¬ìš©
                test_start = split_indices[split_idx]
                test_end = split_indices[split_idx + 1]

                df_test = df.iloc[test_start:test_end].copy()
                split_data: Dict[str, pd.DataFrame] = {'test': df_test}

                # train ë¶€ë¶„ (ì•+ë’¤) ì²˜ë¦¬
                if test_start == 0 or test_end == total_len:
                    df_train = pd.concat(
                        [df.iloc[:test_start], df.iloc[test_end:]],
                        axis=0
                    ).copy()
                    split_data['train'] = df_train
                    all_train_parts.append(df_train)

                    # step1_raw ì €ì¥
                    df_train.to_csv(os.path.join(raw_train_dir, filename), index=False)
                else:
                    df_train_0 = df.iloc[:test_start].copy()
                    df_train_1 = df.iloc[test_end:].copy()
                    split_data['train_0'] = df_train_0
                    split_data['train_1'] = df_train_1
                    all_train_parts.extend([df_train_0, df_train_1])

                    # step1_raw ì €ì¥ (train_0, train_1 êµ¬ë¶„)
                    df_train_0.to_csv(os.path.join(raw_train_dir, f"{base_name}_0.csv"), index=False)
                    df_train_1.to_csv(os.path.join(raw_train_dir, f"{base_name}_1.csv"), index=False)

                # test ì €ì¥
                df_test.to_csv(os.path.join(raw_test_dir, filename), index=False)
                file_split_info[filename] = split_data

            if not all_train_parts:
                print(f"âŒ train ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {folder_name} / {split_name}")
                continue

            # ============================================================
            # 2) train ì „ì²´ì—ì„œ ë¹„ì»¨ë³„ mean/std ê³„ì‚° (0ì€ ê²°ì¸¡ìœ¼ë¡œ ì œì™¸)
            # ============================================================
            df_all_train = pd.concat(all_train_parts, axis=0).reset_index(drop=True)
            norm_stats = compute_beacon_norm_stats(df_all_train, beacon_cols)

            print(f"\nğŸ“ Dataset: {folder_name} / Split {split_name}")
            for f_idx, col in enumerate(beacon_cols):
                print(f"  â–ª {col}: mean={norm_stats[f_idx]['mean']:.3f}, "
                      f"std={norm_stats[f_idx]['std']:.3f}")

            # ============================================================
            # 3) ìŠ¬ë¼ì´ë”© ìœˆë„ìš° + STraTS ìƒ˜í”Œ ìƒì„±
            #    + step2_norm, step3_windows ì €ì¥
            # ============================================================
            train_samples: List[Dict[str, Any]] = []
            test_samples: List[Dict[str, Any]] = []

            # step2_norm / step3_windows ì €ì¥ í´ë”
            norm_root = os.path.join(save_root_strats, 'step2_norm', folder_name, split_name)
            norm_train_dir = os.path.join(norm_root, 'train')
            norm_test_dir = os.path.join(norm_root, 'test')
            os.makedirs(norm_train_dir, exist_ok=True)
            os.makedirs(norm_test_dir, exist_ok=True)

            windows_root = os.path.join(save_root_strats, 'step3_windows', folder_name)
            os.makedirs(windows_root, exist_ok=True)
            # phaseë³„ ìœˆë„ìš° ëª¨ìœ¼ëŠ” ë¦¬ìŠ¤íŠ¸
            all_windows_train: List[np.ndarray] = []
            all_windows_test: List[np.ndarray] = []

            for phase in ['train', 'test']:
                print(f"\nâ–¶ Generating {phase} windows for {folder_name}/{split_name}")

                for filename, split_data in tqdm(file_split_info.items()):
                    base_name = filename.replace('.csv', '')

                    # í•´ë‹¹ phaseì— í•´ë‹¹í•˜ëŠ” DataFrame íŒŒíŠ¸ë“¤ ëª¨ìœ¼ê¸°
                    phase_parts: List[pd.DataFrame] = []
                    phase_part_names: List[str] = []  # íŒŒì¼ëª… êµ¬ë¶„ìš©

                    if phase == 'test':
                        phase_parts.append(split_data['test'])
                        phase_part_names.append(base_name)
                    else:  # train
                        if 'train' in split_data:
                            phase_parts.append(split_data['train'])
                            phase_part_names.append(base_name)
                        else:
                            phase_parts.append(split_data['train_0'])
                            phase_parts.append(split_data['train_1'])
                            phase_part_names.append(base_name + "_0")
                            phase_part_names.append(base_name + "_1")

                    for part_name, df_part in zip(phase_part_names, phase_parts):
                        if len(df_part) < window_size:
                            continue

                        # -------- step2_norm: ì •ê·œí™”ëœ CSV ì €ì¥ --------
                        df_norm = normalize_beacons(df_part, beacon_cols, norm_stats)
                        df_norm_with_zone = df_norm.copy()
                        df_norm_with_zone['Zone'] = df_part['Zone'].values

                        if phase == 'train':
                            norm_path = os.path.join(norm_train_dir, f"{part_name}.csv")
                        else:
                            norm_path = os.path.join(norm_test_dir, f"{part_name}.csv")
                        df_norm_with_zone.to_csv(norm_path, index=False)

                        # -------- ìŠ¬ë¼ì´ë”© ìœˆë„ìš° & STraTS ìƒ˜í”Œ / step3_windows --------
                        values = df_norm[beacon_cols].values   # (T, 5)
                        zones = df_part['Zone'].values         # (T,)

                        for i in range(0, len(values) - window_size + 1, step_size):
                            window = values[i:i + window_size]       # (window_size, 5)
                            zone_label = int(zones[i + window_size // 2])

                            # step3_windows: grid + label ì €ì¥ìš©
                            zone_column = np.full((window_size, 1), zone_label, dtype=np.int32)
                            window_with_label = np.concatenate([window, zone_column], axis=1)  # (T, 6)

                            # STraTS ìƒ˜í”Œ ìƒì„±
                            sample = window_to_strats_sample(
                                window_values=window,
                                zone_label=zone_label,
                                beacon_cols=beacon_cols
                            )
                            if sample is None:
                                continue

                            if phase == 'train':
                                train_samples.append(sample)
                                all_windows_train.append(window_with_label)
                            else:
                                test_samples.append(sample)
                                all_windows_test.append(window_with_label)

                print(f"  â†’ {phase} samples: "
                      f"{len(train_samples) if phase=='train' else len(test_samples)}")

            # step3_windows: npzë¡œ ì €ì¥ (ê¸°ì¡´ all_windows ëŠë‚Œ)
            if all_windows_train:
                all_windows_train_arr = np.stack(all_windows_train, axis=0)  # (N, T, 6)
                np.savez(
                    os.path.join(windows_root, f"train_{split_name}.npz"),
                    data=all_windows_train_arr
                )
                print(f"  âœ… step3_windows train saved: "
                      f"{all_windows_train_arr.shape} -> {os.path.join(windows_root, f'train_{split_name}.npz')}")
            if all_windows_test:
                all_windows_test_arr = np.stack(all_windows_test, axis=0)  # (N, T, 6)
                np.savez(
                    os.path.join(windows_root, f"test_{split_name}.npz"),
                    data=all_windows_test_arr
                )
                print(f"  âœ… step3_windows test saved: "
                      f"{all_windows_test_arr.shape} -> {os.path.join(windows_root, f'test_{split_name}.npz')}")

            # ============================================================
            # 4) STraTS í¬ë§·ìœ¼ë¡œ ìµœì¢… ì €ì¥ (.pt)
            # ============================================================
            save_dir = os.path.join(save_root_strats, 'final_pt', folder_name)
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, f"strats_{split_name}.pt")

            out_obj = {
                "train": train_samples,
                "test": test_samples,
                "norm_stats": norm_stats,
                "meta": {
                    "beacon_cols": beacon_cols,
                    "window_size": window_size,
                    "step_size": step_size,
                    "min_events": min_events_per_sample,
                    "split_name": split_name,
                    "folder_name": folder_name,
                },
            }
            torch.save(out_obj, save_path)
            print(f"\nâœ… Saved final STraTS .pt: {save_path}")
            print(f"   train samples: {len(train_samples)}, "
                  f"test samples: {len(test_samples)}")


if __name__ == "__main__":
    main()
