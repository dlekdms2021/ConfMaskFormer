
16/11/2025 21:33:21 >> Namespace(dataset='beacon', train_frac=0.5, run='1o1', beacon_data_root='./data_split_beacon_strats/final_pt/in-motion', pos_split='pos_1', val_frac=0.0, model_type='strats', load_ckpt_path=None, max_obs=880, hid_dim=32, num_layers=2, num_heads=4, dropout=0.2, attention_dropout=0.2, output_dir='./outputs/strats|pos:pos_1', output_dir_prefix='', seed=2023, max_epochs=100, lr=0.0005, train_batch_size=16, gradient_accumulation_steps=1, eval_batch_size=32, logger=<utils.Logger object at 0x725956f56cd0>)

16/11/2025 21:33:22 >> [BeaconDataset] loaded from ./data_split_beacon_strats/final_pt/in-motion/strats_pos_1.pt
  pos_split = pos_1
  #train = 14472
  #val   = 0
  #test  = 3504
  #classes = 24

16/11/2025 21:33:22 >> Model details:
16/11/2025 21:33:22 >> # parameters: 18956
16/11/2025 21:33:22 >> # trainable parameters: 18956, 100.0%
16/11/2025 21:33:22 >> #params by dtype:
16/11/2025 21:33:22 >> torch.float32: 18956, 100.0%

16/11/2025 21:33:23 >> No. of training batches per epoch = 905

16/11/2025 21:33:31 >> [train] epoch 1 | loss=2.5380

16/11/2025 21:33:32 >> [test] | loss=1.8049, acc=0.2888
16/11/2025 21:33:32 >> [test] epoch 1 | loss=1.8049, acc=0.2888, macroF1=0.2261

16/11/2025 21:33:33 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:33:41 >> [train] epoch 2 | loss=2.0616

16/11/2025 21:33:42 >> [test] | loss=1.6951, acc=0.3094
16/11/2025 21:33:42 >> [test] epoch 2 | loss=1.6951, acc=0.3094, macroF1=0.2328

16/11/2025 21:33:43 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:33:54 >> [train] epoch 3 | loss=1.9458

16/11/2025 21:33:54 >> [test] | loss=1.6376, acc=0.3679
16/11/2025 21:33:54 >> [test] epoch 3 | loss=1.6376, acc=0.3679, macroF1=0.3294

16/11/2025 21:33:56 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:34:05 >> [train] epoch 4 | loss=1.8568

16/11/2025 21:34:06 >> [test] | loss=1.6138, acc=0.3522
16/11/2025 21:34:06 >> [test] epoch 4 | loss=1.6138, acc=0.3522, macroF1=0.3115

16/11/2025 21:34:14 >> [train] epoch 5 | loss=1.8303

16/11/2025 21:34:15 >> [test] | loss=1.5763, acc=0.3542
16/11/2025 21:34:15 >> [test] epoch 5 | loss=1.5763, acc=0.3542, macroF1=0.3049

16/11/2025 21:34:24 >> [train] epoch 6 | loss=1.7858

16/11/2025 21:34:24 >> [test] | loss=1.5296, acc=0.3955
16/11/2025 21:34:24 >> [test] epoch 6 | loss=1.5296, acc=0.3955, macroF1=0.3602

16/11/2025 21:34:26 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:34:34 >> [train] epoch 7 | loss=1.7602

16/11/2025 21:34:35 >> [test] | loss=1.5085, acc=0.3930
16/11/2025 21:34:35 >> [test] epoch 7 | loss=1.5085, acc=0.3930, macroF1=0.3499

16/11/2025 21:34:41 >> [train] epoch 8 | loss=1.7220

16/11/2025 21:34:42 >> [test] | loss=1.4822, acc=0.4110
16/11/2025 21:34:42 >> [test] epoch 8 | loss=1.4822, acc=0.4110, macroF1=0.3907

16/11/2025 21:34:43 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:34:51 >> [train] epoch 9 | loss=1.7202

16/11/2025 21:34:51 >> [test] | loss=1.4609, acc=0.4258
16/11/2025 21:34:51 >> [test] epoch 9 | loss=1.4609, acc=0.4258, macroF1=0.4141

16/11/2025 21:34:52 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:34:59 >> [train] epoch 10 | loss=1.6848

16/11/2025 21:35:00 >> [test] | loss=1.4901, acc=0.4161
16/11/2025 21:35:00 >> [test] epoch 10 | loss=1.4901, acc=0.4161, macroF1=0.3899

16/11/2025 21:35:07 >> [train] epoch 11 | loss=1.6756

16/11/2025 21:35:07 >> [test] | loss=1.4650, acc=0.3981
16/11/2025 21:35:07 >> [test] epoch 11 | loss=1.4650, acc=0.3981, macroF1=0.3602

16/11/2025 21:35:14 >> [train] epoch 12 | loss=1.6737

16/11/2025 21:35:14 >> [test] | loss=1.4542, acc=0.4170
16/11/2025 21:35:14 >> [test] epoch 12 | loss=1.4542, acc=0.4170, macroF1=0.3940

16/11/2025 21:35:27 >> [train] epoch 13 | loss=1.6571

16/11/2025 21:35:28 >> [test] | loss=1.4434, acc=0.4481
16/11/2025 21:35:28 >> [test] epoch 13 | loss=1.4434, acc=0.4481, macroF1=0.4349

16/11/2025 21:35:29 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:35:40 >> [train] epoch 14 | loss=1.6478

16/11/2025 21:35:40 >> [test] | loss=1.4795, acc=0.4181
16/11/2025 21:35:40 >> [test] epoch 14 | loss=1.4795, acc=0.4181, macroF1=0.3965

16/11/2025 21:35:50 >> [train] epoch 15 | loss=1.6448

16/11/2025 21:35:50 >> [test] | loss=1.4460, acc=0.4235
16/11/2025 21:35:50 >> [test] epoch 15 | loss=1.4460, acc=0.4235, macroF1=0.4001

16/11/2025 21:35:57 >> [train] epoch 16 | loss=1.6222

16/11/2025 21:35:58 >> [test] | loss=1.4716, acc=0.4304
16/11/2025 21:35:58 >> [test] epoch 16 | loss=1.4716, acc=0.4304, macroF1=0.4201

16/11/2025 21:36:08 >> [train] epoch 17 | loss=1.6156

16/11/2025 21:36:08 >> [test] | loss=1.4385, acc=0.4461
16/11/2025 21:36:08 >> [test] epoch 17 | loss=1.4385, acc=0.4461, macroF1=0.4320

16/11/2025 21:36:18 >> [train] epoch 18 | loss=1.6070

16/11/2025 21:36:18 >> [test] | loss=1.4697, acc=0.3987
16/11/2025 21:36:18 >> [test] epoch 18 | loss=1.4697, acc=0.3987, macroF1=0.3694

16/11/2025 21:36:25 >> [train] epoch 19 | loss=1.6019

16/11/2025 21:36:26 >> [test] | loss=1.3894, acc=0.4555
16/11/2025 21:36:26 >> [test] epoch 19 | loss=1.3894, acc=0.4555, macroF1=0.4419

16/11/2025 21:36:27 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:36:34 >> [train] epoch 20 | loss=1.5928

16/11/2025 21:36:35 >> [test] | loss=1.4142, acc=0.4335
16/11/2025 21:36:35 >> [test] epoch 20 | loss=1.4142, acc=0.4335, macroF1=0.4077

16/11/2025 21:36:42 >> [train] epoch 21 | loss=1.5999

16/11/2025 21:36:42 >> [test] | loss=1.3777, acc=0.4598
16/11/2025 21:36:42 >> [test] epoch 21 | loss=1.3777, acc=0.4598, macroF1=0.4453

16/11/2025 21:36:43 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:36:50 >> [train] epoch 22 | loss=1.5831

16/11/2025 21:36:51 >> [test] | loss=1.4019, acc=0.4580
16/11/2025 21:36:51 >> [test] epoch 22 | loss=1.4019, acc=0.4580, macroF1=0.4410

16/11/2025 21:36:58 >> [train] epoch 23 | loss=1.5797

16/11/2025 21:36:58 >> [test] | loss=1.3708, acc=0.4572
16/11/2025 21:36:58 >> [test] epoch 23 | loss=1.3708, acc=0.4572, macroF1=0.4332

16/11/2025 21:37:05 >> [train] epoch 24 | loss=1.5650

16/11/2025 21:37:06 >> [test] | loss=1.4004, acc=0.4398
16/11/2025 21:37:06 >> [test] epoch 24 | loss=1.4004, acc=0.4398, macroF1=0.4168

16/11/2025 21:37:13 >> [train] epoch 25 | loss=1.5620

16/11/2025 21:37:13 >> [test] | loss=1.3670, acc=0.4466
16/11/2025 21:37:13 >> [test] epoch 25 | loss=1.3670, acc=0.4466, macroF1=0.4316

16/11/2025 21:37:20 >> [train] epoch 26 | loss=1.5669

16/11/2025 21:37:20 >> [test] | loss=1.3717, acc=0.4555
16/11/2025 21:37:20 >> [test] epoch 26 | loss=1.3717, acc=0.4555, macroF1=0.4401

16/11/2025 21:37:28 >> [train] epoch 27 | loss=1.5544

16/11/2025 21:37:28 >> [test] | loss=1.3897, acc=0.4261
16/11/2025 21:37:28 >> [test] epoch 27 | loss=1.3897, acc=0.4261, macroF1=0.4095

16/11/2025 21:37:36 >> [train] epoch 28 | loss=1.5502

16/11/2025 21:37:36 >> [test] | loss=1.3696, acc=0.4541
16/11/2025 21:37:36 >> [test] epoch 28 | loss=1.3696, acc=0.4541, macroF1=0.4365

16/11/2025 21:37:43 >> [train] epoch 29 | loss=1.5499

16/11/2025 21:37:44 >> [test] | loss=1.3748, acc=0.4344
16/11/2025 21:37:44 >> [test] epoch 29 | loss=1.3748, acc=0.4344, macroF1=0.4167

16/11/2025 21:37:51 >> [train] epoch 30 | loss=1.5448

16/11/2025 21:37:51 >> [test] | loss=1.3752, acc=0.4384
16/11/2025 21:37:51 >> [test] epoch 30 | loss=1.3752, acc=0.4384, macroF1=0.4224

16/11/2025 21:38:02 >> [train] epoch 31 | loss=1.5571

16/11/2025 21:38:03 >> [test] | loss=1.3541, acc=0.4552
16/11/2025 21:38:03 >> [test] epoch 31 | loss=1.3541, acc=0.4552, macroF1=0.4373

16/11/2025 21:38:10 >> [train] epoch 32 | loss=1.5448

16/11/2025 21:38:10 >> [test] | loss=1.3609, acc=0.4580
16/11/2025 21:38:10 >> [test] epoch 32 | loss=1.3609, acc=0.4580, macroF1=0.4415

16/11/2025 21:38:20 >> [train] epoch 33 | loss=1.5545

16/11/2025 21:38:20 >> [test] | loss=1.3684, acc=0.4598
16/11/2025 21:38:20 >> [test] epoch 33 | loss=1.3684, acc=0.4598, macroF1=0.4491

16/11/2025 21:38:21 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:38:28 >> [train] epoch 34 | loss=1.5492

16/11/2025 21:38:29 >> [test] | loss=1.3617, acc=0.4715
16/11/2025 21:38:29 >> [test] epoch 34 | loss=1.3617, acc=0.4715, macroF1=0.4514

16/11/2025 21:38:30 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:38:37 >> [train] epoch 35 | loss=1.5463

16/11/2025 21:38:37 >> [test] | loss=1.3614, acc=0.4592
16/11/2025 21:38:37 >> [test] epoch 35 | loss=1.3614, acc=0.4592, macroF1=0.4396

16/11/2025 21:38:44 >> [train] epoch 36 | loss=1.5412

16/11/2025 21:38:45 >> [test] | loss=1.3627, acc=0.4512
16/11/2025 21:38:45 >> [test] epoch 36 | loss=1.3627, acc=0.4512, macroF1=0.4301

16/11/2025 21:38:52 >> [train] epoch 37 | loss=1.5288

16/11/2025 21:38:52 >> [test] | loss=1.3751, acc=0.4523
16/11/2025 21:38:52 >> [test] epoch 37 | loss=1.3751, acc=0.4523, macroF1=0.4299

16/11/2025 21:38:59 >> [train] epoch 38 | loss=1.5369

16/11/2025 21:38:59 >> [test] | loss=1.3539, acc=0.4463
16/11/2025 21:38:59 >> [test] epoch 38 | loss=1.3539, acc=0.4463, macroF1=0.4351

16/11/2025 21:39:06 >> [train] epoch 39 | loss=1.5267

16/11/2025 21:39:07 >> [test] | loss=1.3941, acc=0.4498
16/11/2025 21:39:07 >> [test] epoch 39 | loss=1.3941, acc=0.4498, macroF1=0.4322

16/11/2025 21:39:15 >> [train] epoch 40 | loss=1.5186

16/11/2025 21:39:15 >> [test] | loss=1.3523, acc=0.4569
16/11/2025 21:39:15 >> [test] epoch 40 | loss=1.3523, acc=0.4569, macroF1=0.4444

16/11/2025 21:39:22 >> [train] epoch 41 | loss=1.5432

16/11/2025 21:39:22 >> [test] | loss=1.3493, acc=0.4612
16/11/2025 21:39:22 >> [test] epoch 41 | loss=1.3493, acc=0.4612, macroF1=0.4475

16/11/2025 21:39:29 >> [train] epoch 42 | loss=1.5315

16/11/2025 21:39:30 >> [test] | loss=1.3553, acc=0.4712
16/11/2025 21:39:30 >> [test] epoch 42 | loss=1.3553, acc=0.4712, macroF1=0.4575

16/11/2025 21:39:31 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:39:38 >> [train] epoch 43 | loss=1.5300

16/11/2025 21:39:39 >> [test] | loss=1.3520, acc=0.4572
16/11/2025 21:39:39 >> [test] epoch 43 | loss=1.3520, acc=0.4572, macroF1=0.4390

16/11/2025 21:39:47 >> [train] epoch 44 | loss=1.5331

16/11/2025 21:39:47 >> [test] | loss=1.3296, acc=0.4503
16/11/2025 21:39:47 >> [test] epoch 44 | loss=1.3296, acc=0.4503, macroF1=0.4364

16/11/2025 21:39:55 >> [train] epoch 45 | loss=1.5313

16/11/2025 21:39:56 >> [test] | loss=1.3572, acc=0.4429
16/11/2025 21:39:56 >> [test] epoch 45 | loss=1.3572, acc=0.4429, macroF1=0.4282

16/11/2025 21:40:05 >> [train] epoch 46 | loss=1.5173

16/11/2025 21:40:06 >> [test] | loss=1.3588, acc=0.4498
16/11/2025 21:40:06 >> [test] epoch 46 | loss=1.3588, acc=0.4498, macroF1=0.4374

16/11/2025 21:40:13 >> [train] epoch 47 | loss=1.5319

16/11/2025 21:40:13 >> [test] | loss=1.3627, acc=0.4595
16/11/2025 21:40:13 >> [test] epoch 47 | loss=1.3627, acc=0.4595, macroF1=0.4457

16/11/2025 21:40:25 >> [train] epoch 48 | loss=1.5301

16/11/2025 21:40:25 >> [test] | loss=1.3462, acc=0.4566
16/11/2025 21:40:25 >> [test] epoch 48 | loss=1.3462, acc=0.4566, macroF1=0.4444

16/11/2025 21:40:33 >> [train] epoch 49 | loss=1.5218

16/11/2025 21:40:33 >> [test] | loss=1.3515, acc=0.4618
16/11/2025 21:40:33 >> [test] epoch 49 | loss=1.3515, acc=0.4618, macroF1=0.4541

16/11/2025 21:40:40 >> [train] epoch 50 | loss=1.5302

16/11/2025 21:40:41 >> [test] | loss=1.3374, acc=0.4478
16/11/2025 21:40:41 >> [test] epoch 50 | loss=1.3374, acc=0.4478, macroF1=0.4312

16/11/2025 21:40:48 >> [train] epoch 51 | loss=1.5188

16/11/2025 21:40:48 >> [test] | loss=1.3538, acc=0.4632
16/11/2025 21:40:48 >> [test] epoch 51 | loss=1.3538, acc=0.4632, macroF1=0.4501

16/11/2025 21:40:55 >> [train] epoch 52 | loss=1.5133

16/11/2025 21:40:55 >> [test] | loss=1.3671, acc=0.4578
16/11/2025 21:40:55 >> [test] epoch 52 | loss=1.3671, acc=0.4578, macroF1=0.4450

16/11/2025 21:41:04 >> [train] epoch 53 | loss=1.5152

16/11/2025 21:41:04 >> [test] | loss=1.3663, acc=0.4526
16/11/2025 21:41:04 >> [test] epoch 53 | loss=1.3663, acc=0.4526, macroF1=0.4394

16/11/2025 21:41:11 >> [train] epoch 54 | loss=1.5109

16/11/2025 21:41:12 >> [test] | loss=1.3579, acc=0.4366
16/11/2025 21:41:12 >> [test] epoch 54 | loss=1.3579, acc=0.4366, macroF1=0.4335

16/11/2025 21:41:22 >> [train] epoch 55 | loss=1.5104

16/11/2025 21:41:22 >> [test] | loss=1.3414, acc=0.4700
16/11/2025 21:41:22 >> [test] epoch 55 | loss=1.3414, acc=0.4700, macroF1=0.4572

16/11/2025 21:41:32 >> [train] epoch 56 | loss=1.5135

16/11/2025 21:41:32 >> [test] | loss=1.3544, acc=0.4538
16/11/2025 21:41:32 >> [test] epoch 56 | loss=1.3544, acc=0.4538, macroF1=0.4375

16/11/2025 21:41:40 >> [train] epoch 57 | loss=1.5113

16/11/2025 21:41:41 >> [test] | loss=1.3618, acc=0.4541
16/11/2025 21:41:41 >> [test] epoch 57 | loss=1.3618, acc=0.4541, macroF1=0.4293

16/11/2025 21:41:48 >> [train] epoch 58 | loss=1.5246

16/11/2025 21:41:48 >> [test] | loss=1.3611, acc=0.4489
16/11/2025 21:41:48 >> [test] epoch 58 | loss=1.3611, acc=0.4489, macroF1=0.4364

16/11/2025 21:41:58 >> [train] epoch 59 | loss=1.4968

16/11/2025 21:41:58 >> [test] | loss=1.3636, acc=0.4435
16/11/2025 21:41:58 >> [test] epoch 59 | loss=1.3636, acc=0.4435, macroF1=0.4327

16/11/2025 21:42:07 >> [train] epoch 60 | loss=1.5023

16/11/2025 21:42:07 >> [test] | loss=1.3621, acc=0.4478
16/11/2025 21:42:07 >> [test] epoch 60 | loss=1.3621, acc=0.4478, macroF1=0.4335

16/11/2025 21:42:15 >> [train] epoch 61 | loss=1.4959

16/11/2025 21:42:16 >> [test] | loss=1.3803, acc=0.4375
16/11/2025 21:42:16 >> [test] epoch 61 | loss=1.3803, acc=0.4375, macroF1=0.4173

16/11/2025 21:42:23 >> [train] epoch 62 | loss=1.5048

16/11/2025 21:42:23 >> [test] | loss=1.3578, acc=0.4606
16/11/2025 21:42:23 >> [test] epoch 62 | loss=1.3578, acc=0.4606, macroF1=0.4492

16/11/2025 21:42:30 >> [train] epoch 63 | loss=1.5060

16/11/2025 21:42:30 >> [test] | loss=1.3683, acc=0.4563
16/11/2025 21:42:30 >> [test] epoch 63 | loss=1.3683, acc=0.4563, macroF1=0.4461

16/11/2025 21:42:37 >> [train] epoch 64 | loss=1.4953

16/11/2025 21:42:37 >> [test] | loss=1.3676, acc=0.4606
16/11/2025 21:42:37 >> [test] epoch 64 | loss=1.3676, acc=0.4606, macroF1=0.4490

16/11/2025 21:42:44 >> [train] epoch 65 | loss=1.5083

16/11/2025 21:42:45 >> [test] | loss=1.3948, acc=0.4355
16/11/2025 21:42:45 >> [test] epoch 65 | loss=1.3948, acc=0.4355, macroF1=0.4219

16/11/2025 21:42:52 >> [train] epoch 66 | loss=1.4970

16/11/2025 21:42:52 >> [test] | loss=1.3484, acc=0.4492
16/11/2025 21:42:52 >> [test] epoch 66 | loss=1.3484, acc=0.4492, macroF1=0.4378

16/11/2025 21:42:59 >> [train] epoch 67 | loss=1.5005

16/11/2025 21:42:59 >> [test] | loss=1.3484, acc=0.4672
16/11/2025 21:42:59 >> [test] epoch 67 | loss=1.3484, acc=0.4672, macroF1=0.4560

16/11/2025 21:43:06 >> [train] epoch 68 | loss=1.5127

16/11/2025 21:43:07 >> [test] | loss=1.3591, acc=0.4575
16/11/2025 21:43:07 >> [test] epoch 68 | loss=1.3591, acc=0.4575, macroF1=0.4448

16/11/2025 21:43:13 >> [train] epoch 69 | loss=1.4976

16/11/2025 21:43:14 >> [test] | loss=1.4288, acc=0.4255
16/11/2025 21:43:14 >> [test] epoch 69 | loss=1.4288, acc=0.4255, macroF1=0.4150

16/11/2025 21:43:21 >> [train] epoch 70 | loss=1.5086

16/11/2025 21:43:21 >> [test] | loss=1.3831, acc=0.4446
16/11/2025 21:43:21 >> [test] epoch 70 | loss=1.3831, acc=0.4446, macroF1=0.4296

16/11/2025 21:43:28 >> [train] epoch 71 | loss=1.5056

16/11/2025 21:43:29 >> [test] | loss=1.3458, acc=0.4638
16/11/2025 21:43:29 >> [test] epoch 71 | loss=1.3458, acc=0.4638, macroF1=0.4514

16/11/2025 21:43:36 >> [train] epoch 72 | loss=1.5032

16/11/2025 21:43:36 >> [test] | loss=1.3874, acc=0.4358
16/11/2025 21:43:36 >> [test] epoch 72 | loss=1.3874, acc=0.4358, macroF1=0.4174

16/11/2025 21:43:43 >> [train] epoch 73 | loss=1.5106

16/11/2025 21:43:43 >> [test] | loss=1.3499, acc=0.4580
16/11/2025 21:43:43 >> [test] epoch 73 | loss=1.3499, acc=0.4580, macroF1=0.4487

16/11/2025 21:43:51 >> [train] epoch 74 | loss=1.5047

16/11/2025 21:43:52 >> [test] | loss=1.3460, acc=0.4549
16/11/2025 21:43:52 >> [test] epoch 74 | loss=1.3460, acc=0.4549, macroF1=0.4466

16/11/2025 21:43:59 >> [train] epoch 75 | loss=1.4975

16/11/2025 21:44:00 >> [test] | loss=1.3550, acc=0.4549
16/11/2025 21:44:00 >> [test] epoch 75 | loss=1.3550, acc=0.4549, macroF1=0.4390

16/11/2025 21:44:07 >> [train] epoch 76 | loss=1.4874

16/11/2025 21:44:07 >> [test] | loss=1.3742, acc=0.4483
16/11/2025 21:44:07 >> [test] epoch 76 | loss=1.3742, acc=0.4483, macroF1=0.4367

16/11/2025 21:44:16 >> [train] epoch 77 | loss=1.4878

16/11/2025 21:44:17 >> [test] | loss=1.3862, acc=0.4469
16/11/2025 21:44:17 >> [test] epoch 77 | loss=1.3862, acc=0.4469, macroF1=0.4291

16/11/2025 21:44:26 >> [train] epoch 78 | loss=1.5075

16/11/2025 21:44:26 >> [test] | loss=1.3798, acc=0.4466
16/11/2025 21:44:26 >> [test] epoch 78 | loss=1.3798, acc=0.4466, macroF1=0.4302

16/11/2025 21:44:33 >> [train] epoch 79 | loss=1.4870

16/11/2025 21:44:33 >> [test] | loss=1.3792, acc=0.4421
16/11/2025 21:44:33 >> [test] epoch 79 | loss=1.3792, acc=0.4421, macroF1=0.4269

16/11/2025 21:44:39 >> [train] epoch 80 | loss=1.5003

16/11/2025 21:44:39 >> [test] | loss=1.3787, acc=0.4552
16/11/2025 21:44:39 >> [test] epoch 80 | loss=1.3787, acc=0.4552, macroF1=0.4422

16/11/2025 21:44:45 >> [train] epoch 81 | loss=1.4958

16/11/2025 21:44:46 >> [test] | loss=1.3652, acc=0.4660
16/11/2025 21:44:46 >> [test] epoch 81 | loss=1.3652, acc=0.4660, macroF1=0.4530

16/11/2025 21:44:52 >> [train] epoch 82 | loss=1.5024

16/11/2025 21:44:52 >> [test] | loss=1.3685, acc=0.4521
16/11/2025 21:44:52 >> [test] epoch 82 | loss=1.3685, acc=0.4521, macroF1=0.4316

16/11/2025 21:45:01 >> [train] epoch 83 | loss=1.4979

16/11/2025 21:45:01 >> [test] | loss=1.3567, acc=0.4580
16/11/2025 21:45:01 >> [test] epoch 83 | loss=1.3567, acc=0.4580, macroF1=0.4377

16/11/2025 21:45:12 >> [train] epoch 84 | loss=1.4996

16/11/2025 21:45:13 >> [test] | loss=1.3772, acc=0.4455
16/11/2025 21:45:13 >> [test] epoch 84 | loss=1.3772, acc=0.4455, macroF1=0.4270

16/11/2025 21:45:21 >> [train] epoch 85 | loss=1.4958

16/11/2025 21:45:21 >> [test] | loss=1.3574, acc=0.4455
16/11/2025 21:45:21 >> [test] epoch 85 | loss=1.3574, acc=0.4455, macroF1=0.4321

16/11/2025 21:45:27 >> [train] epoch 86 | loss=1.4993

16/11/2025 21:45:28 >> [test] | loss=1.3922, acc=0.4478
16/11/2025 21:45:28 >> [test] epoch 86 | loss=1.3922, acc=0.4478, macroF1=0.4309

16/11/2025 21:45:34 >> [train] epoch 87 | loss=1.4937

16/11/2025 21:45:34 >> [test] | loss=1.3607, acc=0.4555
16/11/2025 21:45:34 >> [test] epoch 87 | loss=1.3607, acc=0.4555, macroF1=0.4500

16/11/2025 21:45:44 >> [train] epoch 88 | loss=1.5009

16/11/2025 21:45:45 >> [test] | loss=1.3642, acc=0.4746
16/11/2025 21:45:45 >> [test] epoch 88 | loss=1.3642, acc=0.4746, macroF1=0.4625

16/11/2025 21:45:46 >> Saving ckpt at ./outputs/strats|pos:pos_1/checkpoint_best.bin

16/11/2025 21:45:53 >> [train] epoch 89 | loss=1.5034

16/11/2025 21:45:54 >> [test] | loss=1.3737, acc=0.4589
16/11/2025 21:45:54 >> [test] epoch 89 | loss=1.3737, acc=0.4589, macroF1=0.4529

16/11/2025 21:46:02 >> [train] epoch 90 | loss=1.4991

16/11/2025 21:46:03 >> [test] | loss=1.3708, acc=0.4535
16/11/2025 21:46:03 >> [test] epoch 90 | loss=1.3708, acc=0.4535, macroF1=0.4350

16/11/2025 21:46:12 >> [train] epoch 91 | loss=1.4995

16/11/2025 21:46:12 >> [test] | loss=1.3777, acc=0.4472
16/11/2025 21:46:12 >> [test] epoch 91 | loss=1.3777, acc=0.4472, macroF1=0.4283

16/11/2025 21:46:23 >> [train] epoch 92 | loss=1.4934

16/11/2025 21:46:23 >> [test] | loss=1.4155, acc=0.4438
16/11/2025 21:46:23 >> [test] epoch 92 | loss=1.4155, acc=0.4438, macroF1=0.4255

16/11/2025 21:46:30 >> [train] epoch 93 | loss=1.4921

16/11/2025 21:46:30 >> [test] | loss=1.4306, acc=0.4421
16/11/2025 21:46:30 >> [test] epoch 93 | loss=1.4306, acc=0.4421, macroF1=0.4353

16/11/2025 21:46:39 >> [train] epoch 94 | loss=1.5107

16/11/2025 21:46:39 >> [test] | loss=1.3596, acc=0.4543
16/11/2025 21:46:39 >> [test] epoch 94 | loss=1.3596, acc=0.4543, macroF1=0.4424

16/11/2025 21:46:47 >> [train] epoch 95 | loss=1.5054

16/11/2025 21:46:47 >> [test] | loss=1.3726, acc=0.4512
16/11/2025 21:46:47 >> [test] epoch 95 | loss=1.3726, acc=0.4512, macroF1=0.4395

16/11/2025 21:46:55 >> [train] epoch 96 | loss=1.4910

16/11/2025 21:46:55 >> [test] | loss=1.3783, acc=0.4466
16/11/2025 21:46:55 >> [test] epoch 96 | loss=1.3783, acc=0.4466, macroF1=0.4342

16/11/2025 21:47:05 >> [train] epoch 97 | loss=1.4955

16/11/2025 21:47:05 >> [test] | loss=1.4066, acc=0.4355
16/11/2025 21:47:05 >> [test] epoch 97 | loss=1.4066, acc=0.4355, macroF1=0.4197

16/11/2025 21:47:13 >> [train] epoch 98 | loss=1.5028

16/11/2025 21:47:14 >> [test] | loss=1.3728, acc=0.4515
16/11/2025 21:47:14 >> [test] epoch 98 | loss=1.3728, acc=0.4515, macroF1=0.4368

16/11/2025 21:47:21 >> [train] epoch 99 | loss=1.4967

16/11/2025 21:47:22 >> [test] | loss=1.3734, acc=0.4392
16/11/2025 21:47:22 >> [test] epoch 99 | loss=1.3734, acc=0.4392, macroF1=0.4234

16/11/2025 21:47:28 >> [train] epoch 100 | loss=1.4981

16/11/2025 21:47:28 >> [test] | loss=1.3751, acc=0.4375
16/11/2025 21:47:28 >> [test] epoch 100 | loss=1.3751, acc=0.4375, macroF1=0.4213

16/11/2025 21:47:28 >> [pos_1] Best epoch: 88
16/11/2025 21:47:28 >> Best TEST Acc   : 0.4746
16/11/2025 21:47:28 >> Best TEST MacroF1: 0.4625

16/11/2025 21:47:28 >> === Classification Report (best) ===
              precision    recall  f1-score   support

           0     0.7018    0.5479    0.6154       146
           1     0.5166    0.7466    0.6106       146
           2     0.5328    0.5000    0.5159       146
           3     0.5580    0.5274    0.5423       146
           4     0.5500    0.6027    0.5752       146
           5     0.4612    0.7329    0.5661       146
           6     0.4645    0.4932    0.4784       146
           7     0.4107    0.1575    0.2277       146
           8     0.3796    0.3562    0.3675       146
           9     0.4000    0.5753    0.4719       146
          10     0.5231    0.4658    0.4928       146
          11     0.5273    0.5959    0.5595       146
          12     0.3588    0.3219    0.3394       146
          13     0.3867    0.1986    0.2624       146
          14     0.4362    0.2808    0.3417       146
          15     0.4746    0.5753    0.5201       146
          16     0.6545    0.4932    0.5625       146
          17     0.3964    0.7466    0.5178       146
          18     0.5784    0.4041    0.4758       146
          19     0.3186    0.4452    0.3714       146
          20     0.2887    0.1918    0.2305       146
          21     0.5410    0.2260    0.3188       146
          22     0.6471    0.6027    0.6241       146
          23     0.4467    0.6027    0.5131       146

    accuracy                         0.4746      3504
   macro avg     0.4814    0.4746    0.4625      3504
weighted avg     0.4814    0.4746    0.4625      3504

