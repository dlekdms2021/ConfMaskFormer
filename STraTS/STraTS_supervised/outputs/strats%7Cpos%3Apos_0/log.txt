
16/11/2025 21:31:13 >> Namespace(dataset='beacon', train_frac=0.5, run='1o1', beacon_data_root='./data_split_beacon_strats/final_pt/in-motion', pos_split='pos_0', val_frac=0.0, model_type='strats', load_ckpt_path=None, max_obs=880, hid_dim=32, num_layers=2, num_heads=4, dropout=0.2, attention_dropout=0.2, output_dir='./outputs/strats|pos:pos_0', output_dir_prefix='', seed=2023, max_epochs=100, lr=0.0005, train_batch_size=16, gradient_accumulation_steps=1, eval_batch_size=32, logger=<utils.Logger object at 0x7b209efb41d0>)

16/11/2025 21:31:13 >> [BeaconDataset] loaded from ./data_split_beacon_strats/final_pt/in-motion/strats_pos_0.pt
  pos_split = pos_0
  #train = 14688
  #val   = 0
  #test  = 3504
  #classes = 24

16/11/2025 21:31:13 >> Model details:
16/11/2025 21:31:13 >> # parameters: 18956
16/11/2025 21:31:13 >> # trainable parameters: 18956, 100.0%
16/11/2025 21:31:13 >> #params by dtype:
16/11/2025 21:31:13 >> torch.float32: 18956, 100.0%

16/11/2025 21:31:14 >> No. of training batches per epoch = 918

16/11/2025 21:31:22 >> [train] epoch 1 | loss=2.5424

16/11/2025 21:31:22 >> [test] | loss=1.8665, acc=0.2078
16/11/2025 21:31:22 >> [test] epoch 1 | loss=1.8665, acc=0.2078, macroF1=0.1450

16/11/2025 21:31:23 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:31:33 >> [train] epoch 2 | loss=2.0750

16/11/2025 21:31:33 >> [test] | loss=1.6880, acc=0.2857
16/11/2025 21:31:33 >> [test] epoch 2 | loss=1.6880, acc=0.2857, macroF1=0.2117

16/11/2025 21:31:34 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:31:47 >> [train] epoch 3 | loss=1.9507

16/11/2025 21:31:47 >> [test] | loss=1.5834, acc=0.3273
16/11/2025 21:31:47 >> [test] epoch 3 | loss=1.5834, acc=0.3273, macroF1=0.2953

16/11/2025 21:31:49 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:32:00 >> [train] epoch 4 | loss=1.8770

16/11/2025 21:32:00 >> [test] | loss=1.5365, acc=0.3827
16/11/2025 21:32:00 >> [test] epoch 4 | loss=1.5365, acc=0.3827, macroF1=0.3436

16/11/2025 21:32:02 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:32:11 >> [train] epoch 5 | loss=1.8295

16/11/2025 21:32:11 >> [test] | loss=1.5311, acc=0.3687
16/11/2025 21:32:11 >> [test] epoch 5 | loss=1.5311, acc=0.3687, macroF1=0.3309

16/11/2025 21:32:19 >> [train] epoch 6 | loss=1.7812

16/11/2025 21:32:19 >> [test] | loss=1.5407, acc=0.3716
16/11/2025 21:32:19 >> [test] epoch 6 | loss=1.5407, acc=0.3716, macroF1=0.3190

16/11/2025 21:32:27 >> [train] epoch 7 | loss=1.7596

16/11/2025 21:32:28 >> [test] | loss=1.4977, acc=0.3821
16/11/2025 21:32:28 >> [test] epoch 7 | loss=1.4977, acc=0.3821, macroF1=0.3558

16/11/2025 21:32:29 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:32:37 >> [train] epoch 8 | loss=1.7345

16/11/2025 21:32:38 >> [test] | loss=1.5277, acc=0.3562
16/11/2025 21:32:38 >> [test] epoch 8 | loss=1.5277, acc=0.3562, macroF1=0.3220

16/11/2025 21:32:45 >> [train] epoch 9 | loss=1.7275

16/11/2025 21:32:45 >> [test] | loss=1.4782, acc=0.4035
16/11/2025 21:32:45 >> [test] epoch 9 | loss=1.4782, acc=0.4035, macroF1=0.3681

16/11/2025 21:32:47 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:32:54 >> [train] epoch 10 | loss=1.7027

16/11/2025 21:32:55 >> [test] | loss=1.4501, acc=0.4104
16/11/2025 21:32:55 >> [test] epoch 10 | loss=1.4501, acc=0.4104, macroF1=0.3944

16/11/2025 21:32:56 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:33:01 >> [train] epoch 11 | loss=1.6813

16/11/2025 21:33:02 >> [test] | loss=1.4910, acc=0.3924
16/11/2025 21:33:02 >> [test] epoch 11 | loss=1.4910, acc=0.3924, macroF1=0.3644

16/11/2025 21:33:07 >> [train] epoch 12 | loss=1.6728

16/11/2025 21:33:07 >> [test] | loss=1.4474, acc=0.4167
16/11/2025 21:33:07 >> [test] epoch 12 | loss=1.4474, acc=0.4167, macroF1=0.3908

16/11/2025 21:33:13 >> [train] epoch 13 | loss=1.6514

16/11/2025 21:33:13 >> [test] | loss=1.4543, acc=0.4292
16/11/2025 21:33:13 >> [test] epoch 13 | loss=1.4543, acc=0.4292, macroF1=0.3899

16/11/2025 21:33:19 >> [train] epoch 14 | loss=1.6549

16/11/2025 21:33:19 >> [test] | loss=1.4518, acc=0.4061
16/11/2025 21:33:19 >> [test] epoch 14 | loss=1.4518, acc=0.4061, macroF1=0.3684

16/11/2025 21:33:24 >> [train] epoch 15 | loss=1.6430

16/11/2025 21:33:25 >> [test] | loss=1.4245, acc=0.4307
16/11/2025 21:33:25 >> [test] epoch 15 | loss=1.4245, acc=0.4307, macroF1=0.4203

16/11/2025 21:33:26 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:33:33 >> [train] epoch 16 | loss=1.6226

16/11/2025 21:33:33 >> [test] | loss=1.4234, acc=0.4155
16/11/2025 21:33:33 >> [test] epoch 16 | loss=1.4234, acc=0.4155, macroF1=0.3938

16/11/2025 21:33:43 >> [train] epoch 17 | loss=1.6273

16/11/2025 21:33:44 >> [test] | loss=1.4410, acc=0.4212
16/11/2025 21:33:44 >> [test] epoch 17 | loss=1.4410, acc=0.4212, macroF1=0.4031

16/11/2025 21:33:51 >> [train] epoch 18 | loss=1.6050

16/11/2025 21:33:51 >> [test] | loss=1.4109, acc=0.4278
16/11/2025 21:33:51 >> [test] epoch 18 | loss=1.4109, acc=0.4278, macroF1=0.4082

16/11/2025 21:33:58 >> [train] epoch 19 | loss=1.6041

16/11/2025 21:33:59 >> [test] | loss=1.4101, acc=0.4287
16/11/2025 21:33:59 >> [test] epoch 19 | loss=1.4101, acc=0.4287, macroF1=0.4214

16/11/2025 21:34:00 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:34:07 >> [train] epoch 20 | loss=1.5992

16/11/2025 21:34:07 >> [test] | loss=1.4224, acc=0.3984
16/11/2025 21:34:07 >> [test] epoch 20 | loss=1.4224, acc=0.3984, macroF1=0.3728

16/11/2025 21:34:14 >> [train] epoch 21 | loss=1.6062

16/11/2025 21:34:14 >> [test] | loss=1.4117, acc=0.4035
16/11/2025 21:34:14 >> [test] epoch 21 | loss=1.4117, acc=0.4035, macroF1=0.3958

16/11/2025 21:34:21 >> [train] epoch 22 | loss=1.5942

16/11/2025 21:34:22 >> [test] | loss=1.4153, acc=0.4007
16/11/2025 21:34:22 >> [test] epoch 22 | loss=1.4153, acc=0.4007, macroF1=0.3756

16/11/2025 21:34:28 >> [train] epoch 23 | loss=1.5738

16/11/2025 21:34:28 >> [test] | loss=1.4085, acc=0.4361
16/11/2025 21:34:29 >> [test] epoch 23 | loss=1.4085, acc=0.4361, macroF1=0.4134

16/11/2025 21:34:36 >> [train] epoch 24 | loss=1.5666

16/11/2025 21:34:36 >> [test] | loss=1.3764, acc=0.4523
16/11/2025 21:34:36 >> [test] epoch 24 | loss=1.3764, acc=0.4523, macroF1=0.4423

16/11/2025 21:34:38 >> Saving ckpt at ./outputs/strats|pos:pos_0/checkpoint_best.bin

16/11/2025 21:34:49 >> [train] epoch 25 | loss=1.5649

16/11/2025 21:34:50 >> [test] | loss=1.4194, acc=0.4204
16/11/2025 21:34:50 >> [test] epoch 25 | loss=1.4194, acc=0.4204, macroF1=0.4055

16/11/2025 21:34:56 >> [train] epoch 26 | loss=1.5666

16/11/2025 21:34:57 >> [test] | loss=1.4169, acc=0.4255
16/11/2025 21:34:57 >> [test] epoch 26 | loss=1.4169, acc=0.4255, macroF1=0.4036

16/11/2025 21:35:04 >> [train] epoch 27 | loss=1.5601

16/11/2025 21:35:04 >> [test] | loss=1.3816, acc=0.4292
16/11/2025 21:35:04 >> [test] epoch 27 | loss=1.3816, acc=0.4292, macroF1=0.4204

16/11/2025 21:35:11 >> [train] epoch 28 | loss=1.5487

16/11/2025 21:35:12 >> [test] | loss=1.3874, acc=0.4309
16/11/2025 21:35:12 >> [test] epoch 28 | loss=1.3874, acc=0.4309, macroF1=0.4167

16/11/2025 21:35:19 >> [train] epoch 29 | loss=1.5469

16/11/2025 21:35:19 >> [test] | loss=1.4257, acc=0.4264
16/11/2025 21:35:19 >> [test] epoch 29 | loss=1.4257, acc=0.4264, macroF1=0.4095

16/11/2025 21:35:26 >> [train] epoch 30 | loss=1.5577

16/11/2025 21:35:26 >> [test] | loss=1.4313, acc=0.4061
16/11/2025 21:35:26 >> [test] epoch 30 | loss=1.4313, acc=0.4061, macroF1=0.3791

16/11/2025 21:35:33 >> [train] epoch 31 | loss=1.5627

16/11/2025 21:35:33 >> [test] | loss=1.3957, acc=0.4235
16/11/2025 21:35:33 >> [test] epoch 31 | loss=1.3957, acc=0.4235, macroF1=0.4179

16/11/2025 21:35:40 >> [train] epoch 32 | loss=1.5413

16/11/2025 21:35:40 >> [test] | loss=1.3955, acc=0.4061
16/11/2025 21:35:40 >> [test] epoch 32 | loss=1.3955, acc=0.4061, macroF1=0.3988

16/11/2025 21:35:47 >> [train] epoch 33 | loss=1.5459

16/11/2025 21:35:47 >> [test] | loss=1.3917, acc=0.4341
16/11/2025 21:35:47 >> [test] epoch 33 | loss=1.3917, acc=0.4341, macroF1=0.4214

16/11/2025 21:35:54 >> [train] epoch 34 | loss=1.5458

16/11/2025 21:35:55 >> [test] | loss=1.4060, acc=0.4232
16/11/2025 21:35:55 >> [test] epoch 34 | loss=1.4060, acc=0.4232, macroF1=0.4083

16/11/2025 21:36:02 >> [train] epoch 35 | loss=1.5460

16/11/2025 21:36:02 >> [test] | loss=1.3905, acc=0.4424
16/11/2025 21:36:02 >> [test] epoch 35 | loss=1.3905, acc=0.4424, macroF1=0.4218

16/11/2025 21:36:09 >> [train] epoch 36 | loss=1.5500

16/11/2025 21:36:09 >> [test] | loss=1.3920, acc=0.4312
16/11/2025 21:36:09 >> [test] epoch 36 | loss=1.3920, acc=0.4312, macroF1=0.4115

16/11/2025 21:36:16 >> [train] epoch 37 | loss=1.5277

16/11/2025 21:36:16 >> [test] | loss=1.4075, acc=0.4329
16/11/2025 21:36:16 >> [test] epoch 37 | loss=1.4075, acc=0.4329, macroF1=0.4227

16/11/2025 21:36:23 >> [train] epoch 38 | loss=1.5309

16/11/2025 21:36:23 >> [test] | loss=1.4489, acc=0.4181
16/11/2025 21:36:23 >> [test] epoch 38 | loss=1.4489, acc=0.4181, macroF1=0.3912

16/11/2025 21:36:30 >> [train] epoch 39 | loss=1.5386

16/11/2025 21:36:30 >> [test] | loss=1.4129, acc=0.4318
16/11/2025 21:36:30 >> [test] epoch 39 | loss=1.4129, acc=0.4318, macroF1=0.4189

16/11/2025 21:36:37 >> [train] epoch 40 | loss=1.5323

16/11/2025 21:36:38 >> [test] | loss=1.4027, acc=0.4147
16/11/2025 21:36:38 >> [test] epoch 40 | loss=1.4027, acc=0.4147, macroF1=0.4096

16/11/2025 21:36:45 >> [train] epoch 41 | loss=1.5280

16/11/2025 21:36:45 >> [test] | loss=1.4622, acc=0.4227
16/11/2025 21:36:45 >> [test] epoch 41 | loss=1.4622, acc=0.4227, macroF1=0.4028

16/11/2025 21:36:52 >> [train] epoch 42 | loss=1.5486

16/11/2025 21:36:52 >> [test] | loss=1.4625, acc=0.3890
16/11/2025 21:36:52 >> [test] epoch 42 | loss=1.4625, acc=0.3890, macroF1=0.3597

16/11/2025 21:37:00 >> [train] epoch 43 | loss=1.5190

16/11/2025 21:37:00 >> [test] | loss=1.4021, acc=0.4318
16/11/2025 21:37:00 >> [test] epoch 43 | loss=1.4021, acc=0.4318, macroF1=0.4165

16/11/2025 21:37:07 >> [train] epoch 44 | loss=1.5337

16/11/2025 21:37:07 >> [test] | loss=1.3806, acc=0.4395
16/11/2025 21:37:07 >> [test] epoch 44 | loss=1.3806, acc=0.4395, macroF1=0.4183

16/11/2025 21:37:15 >> [train] epoch 45 | loss=1.5304

16/11/2025 21:37:15 >> [test] | loss=1.4173, acc=0.4195
16/11/2025 21:37:15 >> [test] epoch 45 | loss=1.4173, acc=0.4195, macroF1=0.4073

16/11/2025 21:37:22 >> [train] epoch 46 | loss=1.5409

16/11/2025 21:37:22 >> [test] | loss=1.3987, acc=0.4329
16/11/2025 21:37:22 >> [test] epoch 46 | loss=1.3987, acc=0.4329, macroF1=0.4100

16/11/2025 21:37:29 >> [train] epoch 47 | loss=1.5182

16/11/2025 21:37:30 >> [test] | loss=1.3916, acc=0.4421
16/11/2025 21:37:30 >> [test] epoch 47 | loss=1.3916, acc=0.4421, macroF1=0.4325

16/11/2025 21:37:39 >> [train] epoch 48 | loss=1.5349

16/11/2025 21:37:39 >> [test] | loss=1.4108, acc=0.4150
16/11/2025 21:37:39 >> [test] epoch 48 | loss=1.4108, acc=0.4150, macroF1=0.4020

16/11/2025 21:37:46 >> [train] epoch 49 | loss=1.5265

16/11/2025 21:37:47 >> [test] | loss=1.4210, acc=0.4321
16/11/2025 21:37:47 >> [test] epoch 49 | loss=1.4210, acc=0.4321, macroF1=0.4222

16/11/2025 21:37:54 >> [train] epoch 50 | loss=1.5237

16/11/2025 21:37:55 >> [test] | loss=1.3988, acc=0.4398
16/11/2025 21:37:55 >> [test] epoch 50 | loss=1.3988, acc=0.4398, macroF1=0.4201

16/11/2025 21:38:01 >> [train] epoch 51 | loss=1.5193

16/11/2025 21:38:02 >> [test] | loss=1.4081, acc=0.4058
16/11/2025 21:38:02 >> [test] epoch 51 | loss=1.4081, acc=0.4058, macroF1=0.3961

16/11/2025 21:38:09 >> [train] epoch 52 | loss=1.5199

16/11/2025 21:38:09 >> [test] | loss=1.4122, acc=0.3941
16/11/2025 21:38:09 >> [test] epoch 52 | loss=1.4122, acc=0.3941, macroF1=0.3814

16/11/2025 21:38:16 >> [train] epoch 53 | loss=1.5223

16/11/2025 21:38:16 >> [test] | loss=1.4183, acc=0.4324
16/11/2025 21:38:16 >> [test] epoch 53 | loss=1.4183, acc=0.4324, macroF1=0.4147

16/11/2025 21:38:23 >> [train] epoch 54 | loss=1.5253

16/11/2025 21:38:24 >> [test] | loss=1.4486, acc=0.4201
16/11/2025 21:38:24 >> [test] epoch 54 | loss=1.4486, acc=0.4201, macroF1=0.4100

16/11/2025 21:38:30 >> [train] epoch 55 | loss=1.5310

16/11/2025 21:38:31 >> [test] | loss=1.4049, acc=0.4281
16/11/2025 21:38:31 >> [test] epoch 55 | loss=1.4049, acc=0.4281, macroF1=0.4172

16/11/2025 21:38:38 >> [train] epoch 56 | loss=1.5163

16/11/2025 21:38:38 >> [test] | loss=1.4241, acc=0.4238
16/11/2025 21:38:38 >> [test] epoch 56 | loss=1.4241, acc=0.4238, macroF1=0.4104

16/11/2025 21:38:45 >> [train] epoch 57 | loss=1.5168

16/11/2025 21:38:46 >> [test] | loss=1.4120, acc=0.4130
16/11/2025 21:38:46 >> [test] epoch 57 | loss=1.4120, acc=0.4130, macroF1=0.3989

16/11/2025 21:38:53 >> [train] epoch 58 | loss=1.5156

16/11/2025 21:38:53 >> [test] | loss=1.3978, acc=0.4287
16/11/2025 21:38:53 >> [test] epoch 58 | loss=1.3978, acc=0.4287, macroF1=0.4181

16/11/2025 21:39:00 >> [train] epoch 59 | loss=1.5168

16/11/2025 21:39:00 >> [test] | loss=1.3980, acc=0.4221
16/11/2025 21:39:00 >> [test] epoch 59 | loss=1.3980, acc=0.4221, macroF1=0.4133

16/11/2025 21:39:10 >> [train] epoch 60 | loss=1.5070

16/11/2025 21:39:11 >> [test] | loss=1.4210, acc=0.4264
16/11/2025 21:39:11 >> [test] epoch 60 | loss=1.4210, acc=0.4264, macroF1=0.4129

16/11/2025 21:39:19 >> [train] epoch 61 | loss=1.4994

16/11/2025 21:39:19 >> [test] | loss=1.4020, acc=0.4275
16/11/2025 21:39:19 >> [test] epoch 61 | loss=1.4020, acc=0.4275, macroF1=0.4131

16/11/2025 21:39:26 >> [train] epoch 62 | loss=1.5080

16/11/2025 21:39:27 >> [test] | loss=1.4081, acc=0.4207
16/11/2025 21:39:27 >> [test] epoch 62 | loss=1.4081, acc=0.4207, macroF1=0.4119

16/11/2025 21:39:33 >> [train] epoch 63 | loss=1.5060

16/11/2025 21:39:34 >> [test] | loss=1.4690, acc=0.3799
16/11/2025 21:39:34 >> [test] epoch 63 | loss=1.4690, acc=0.3799, macroF1=0.3577

16/11/2025 21:39:42 >> [train] epoch 64 | loss=1.5210

16/11/2025 21:39:42 >> [test] | loss=1.4000, acc=0.4241
16/11/2025 21:39:42 >> [test] epoch 64 | loss=1.4000, acc=0.4241, macroF1=0.4068

16/11/2025 21:39:49 >> [train] epoch 65 | loss=1.5132

16/11/2025 21:39:50 >> [test] | loss=1.4383, acc=0.4144
16/11/2025 21:39:50 >> [test] epoch 65 | loss=1.4383, acc=0.4144, macroF1=0.3992

16/11/2025 21:39:57 >> [train] epoch 66 | loss=1.5050

16/11/2025 21:39:57 >> [test] | loss=1.4309, acc=0.4352
16/11/2025 21:39:57 >> [test] epoch 66 | loss=1.4309, acc=0.4352, macroF1=0.4125

16/11/2025 21:40:05 >> [train] epoch 67 | loss=1.5176

16/11/2025 21:40:05 >> [test] | loss=1.3992, acc=0.4247
16/11/2025 21:40:05 >> [test] epoch 67 | loss=1.3992, acc=0.4247, macroF1=0.4125

16/11/2025 21:40:12 >> [train] epoch 68 | loss=1.5058

16/11/2025 21:40:13 >> [test] | loss=1.4467, acc=0.4209
16/11/2025 21:40:13 >> [test] epoch 68 | loss=1.4467, acc=0.4209, macroF1=0.4051

16/11/2025 21:40:19 >> [train] epoch 69 | loss=1.5103

16/11/2025 21:40:20 >> [test] | loss=1.4353, acc=0.4298
16/11/2025 21:40:20 >> [test] epoch 69 | loss=1.4353, acc=0.4298, macroF1=0.4149

16/11/2025 21:40:27 >> [train] epoch 70 | loss=1.5120

16/11/2025 21:40:28 >> [test] | loss=1.4609, acc=0.4218
16/11/2025 21:40:28 >> [test] epoch 70 | loss=1.4609, acc=0.4218, macroF1=0.4080

16/11/2025 21:40:36 >> [train] epoch 71 | loss=1.5087

16/11/2025 21:40:36 >> [test] | loss=1.3942, acc=0.4364
16/11/2025 21:40:36 >> [test] epoch 71 | loss=1.3942, acc=0.4364, macroF1=0.4318

16/11/2025 21:40:43 >> [train] epoch 72 | loss=1.5127

16/11/2025 21:40:44 >> [test] | loss=1.4612, acc=0.4172
16/11/2025 21:40:44 >> [test] epoch 72 | loss=1.4612, acc=0.4172, macroF1=0.4022

16/11/2025 21:40:51 >> [train] epoch 73 | loss=1.5197

16/11/2025 21:40:51 >> [test] | loss=1.4259, acc=0.4232
16/11/2025 21:40:51 >> [test] epoch 73 | loss=1.4259, acc=0.4232, macroF1=0.4097

16/11/2025 21:40:59 >> [train] epoch 74 | loss=1.5230

16/11/2025 21:40:59 >> [test] | loss=1.4261, acc=0.4372
16/11/2025 21:40:59 >> [test] epoch 74 | loss=1.4261, acc=0.4372, macroF1=0.4246

16/11/2025 21:41:06 >> [train] epoch 75 | loss=1.5147

16/11/2025 21:41:07 >> [test] | loss=1.4288, acc=0.4244
16/11/2025 21:41:07 >> [test] epoch 75 | loss=1.4288, acc=0.4244, macroF1=0.4180

16/11/2025 21:41:14 >> [train] epoch 76 | loss=1.5092

16/11/2025 21:41:15 >> [test] | loss=1.4260, acc=0.4204
16/11/2025 21:41:15 >> [test] epoch 76 | loss=1.4260, acc=0.4204, macroF1=0.4125

16/11/2025 21:41:24 >> [train] epoch 77 | loss=1.5130

16/11/2025 21:41:24 >> [test] | loss=1.4497, acc=0.3975
16/11/2025 21:41:24 >> [test] epoch 77 | loss=1.4497, acc=0.3975, macroF1=0.3762

16/11/2025 21:41:32 >> [train] epoch 78 | loss=1.5090

16/11/2025 21:41:33 >> [test] | loss=1.4584, acc=0.4087
16/11/2025 21:41:33 >> [test] epoch 78 | loss=1.4584, acc=0.4087, macroF1=0.3947

16/11/2025 21:41:40 >> [train] epoch 79 | loss=1.5054

16/11/2025 21:41:40 >> [test] | loss=1.4501, acc=0.3938
16/11/2025 21:41:40 >> [test] epoch 79 | loss=1.4501, acc=0.3938, macroF1=0.3745

16/11/2025 21:41:47 >> [train] epoch 80 | loss=1.5067

16/11/2025 21:41:48 >> [test] | loss=1.4328, acc=0.4038
16/11/2025 21:41:48 >> [test] epoch 80 | loss=1.4328, acc=0.4038, macroF1=0.3849

16/11/2025 21:41:55 >> [train] epoch 81 | loss=1.4982

16/11/2025 21:41:55 >> [test] | loss=1.4713, acc=0.4269
16/11/2025 21:41:55 >> [test] epoch 81 | loss=1.4713, acc=0.4269, macroF1=0.4088

16/11/2025 21:42:02 >> [train] epoch 82 | loss=1.5002

16/11/2025 21:42:02 >> [test] | loss=1.4295, acc=0.4229
16/11/2025 21:42:02 >> [test] epoch 82 | loss=1.4295, acc=0.4229, macroF1=0.4115

16/11/2025 21:42:09 >> [train] epoch 83 | loss=1.5058

16/11/2025 21:42:09 >> [test] | loss=1.4784, acc=0.4007
16/11/2025 21:42:09 >> [test] epoch 83 | loss=1.4784, acc=0.4007, macroF1=0.3782

16/11/2025 21:42:16 >> [train] epoch 84 | loss=1.5112

16/11/2025 21:42:17 >> [test] | loss=1.4962, acc=0.3961
16/11/2025 21:42:17 >> [test] epoch 84 | loss=1.4962, acc=0.3961, macroF1=0.3764

16/11/2025 21:42:24 >> [train] epoch 85 | loss=1.5074

16/11/2025 21:42:24 >> [test] | loss=1.4058, acc=0.4309
16/11/2025 21:42:24 >> [test] epoch 85 | loss=1.4058, acc=0.4309, macroF1=0.4112

16/11/2025 21:42:34 >> [train] epoch 86 | loss=1.5065

16/11/2025 21:42:34 >> [test] | loss=1.4910, acc=0.3779
16/11/2025 21:42:34 >> [test] epoch 86 | loss=1.4910, acc=0.3779, macroF1=0.3558

16/11/2025 21:42:41 >> [train] epoch 87 | loss=1.5050

16/11/2025 21:42:42 >> [test] | loss=1.4211, acc=0.4278
16/11/2025 21:42:42 >> [test] epoch 87 | loss=1.4211, acc=0.4278, macroF1=0.4168

16/11/2025 21:42:49 >> [train] epoch 88 | loss=1.5082

16/11/2025 21:42:49 >> [test] | loss=1.4711, acc=0.3964
16/11/2025 21:42:49 >> [test] epoch 88 | loss=1.4711, acc=0.3964, macroF1=0.3787

16/11/2025 21:42:56 >> [train] epoch 89 | loss=1.5026

16/11/2025 21:42:57 >> [test] | loss=1.4372, acc=0.4124
16/11/2025 21:42:57 >> [test] epoch 89 | loss=1.4372, acc=0.4124, macroF1=0.3946

16/11/2025 21:43:04 >> [train] epoch 90 | loss=1.4996

16/11/2025 21:43:04 >> [test] | loss=1.4463, acc=0.4167
16/11/2025 21:43:04 >> [test] epoch 90 | loss=1.4463, acc=0.4167, macroF1=0.4026

16/11/2025 21:43:11 >> [train] epoch 91 | loss=1.4957

16/11/2025 21:43:11 >> [test] | loss=1.4277, acc=0.4255
16/11/2025 21:43:11 >> [test] epoch 91 | loss=1.4277, acc=0.4255, macroF1=0.4195

16/11/2025 21:43:19 >> [train] epoch 92 | loss=1.5122

16/11/2025 21:43:19 >> [test] | loss=1.5464, acc=0.3818
16/11/2025 21:43:19 >> [test] epoch 92 | loss=1.5464, acc=0.3818, macroF1=0.3624

16/11/2025 21:43:26 >> [train] epoch 93 | loss=1.5084

16/11/2025 21:43:27 >> [test] | loss=1.4948, acc=0.3907
16/11/2025 21:43:27 >> [test] epoch 93 | loss=1.4948, acc=0.3907, macroF1=0.3798

16/11/2025 21:43:34 >> [train] epoch 94 | loss=1.5042

16/11/2025 21:43:34 >> [test] | loss=1.5123, acc=0.4155
16/11/2025 21:43:34 >> [test] epoch 94 | loss=1.5123, acc=0.4155, macroF1=0.4036

16/11/2025 21:43:41 >> [train] epoch 95 | loss=1.5064

16/11/2025 21:43:41 >> [test] | loss=1.4574, acc=0.4207
16/11/2025 21:43:41 >> [test] epoch 95 | loss=1.4574, acc=0.4207, macroF1=0.4027

16/11/2025 21:43:50 >> [train] epoch 96 | loss=1.4987

16/11/2025 21:43:50 >> [test] | loss=1.4725, acc=0.4249
16/11/2025 21:43:50 >> [test] epoch 96 | loss=1.4725, acc=0.4249, macroF1=0.4068

16/11/2025 21:43:57 >> [train] epoch 97 | loss=1.5071

16/11/2025 21:43:58 >> [test] | loss=1.4552, acc=0.4304
16/11/2025 21:43:58 >> [test] epoch 97 | loss=1.4552, acc=0.4304, macroF1=0.4136

16/11/2025 21:44:05 >> [train] epoch 98 | loss=1.5024

16/11/2025 21:44:05 >> [test] | loss=1.4246, acc=0.4207
16/11/2025 21:44:05 >> [test] epoch 98 | loss=1.4246, acc=0.4207, macroF1=0.4100

16/11/2025 21:44:13 >> [train] epoch 99 | loss=1.5050

16/11/2025 21:44:13 >> [test] | loss=1.4470, acc=0.4209
16/11/2025 21:44:13 >> [test] epoch 99 | loss=1.4470, acc=0.4209, macroF1=0.4104

16/11/2025 21:44:20 >> [train] epoch 100 | loss=1.5043

16/11/2025 21:44:21 >> [test] | loss=1.3925, acc=0.4309
16/11/2025 21:44:21 >> [test] epoch 100 | loss=1.3925, acc=0.4309, macroF1=0.4146

16/11/2025 21:44:21 >> [pos_0] Best epoch: 24
16/11/2025 21:44:21 >> Best TEST Acc   : 0.4523
16/11/2025 21:44:21 >> Best TEST MacroF1: 0.4423

16/11/2025 21:44:21 >> === Classification Report (best) ===
              precision    recall  f1-score   support

           0     0.7236    0.6096    0.6617       146
           1     0.5124    0.7055    0.5937       146
           2     0.5140    0.3767    0.4348       146
           3     0.6562    0.5753    0.6131       146
           4     0.5924    0.6370    0.6139       146
           5     0.3286    0.4795    0.3900       146
           6     0.6710    0.7123    0.6910       146
           7     0.3393    0.2603    0.2946       146
           8     0.4219    0.3699    0.3942       146
           9     0.5600    0.4795    0.5166       146
          10     0.4858    0.7055    0.5754       146
          11     0.4815    0.4452    0.4626       146
          12     0.4326    0.6370    0.5152       146
          13     0.8837    0.2603    0.4021       146
          14     0.3731    0.3425    0.3571       146
          15     0.1932    0.1164    0.1453       146
          16     0.3430    0.4041    0.3711       146
          17     0.4806    0.6781    0.5625       146
          18     0.4753    0.5274    0.5000       146
          19     0.1947    0.1507    0.1699       146
          20     0.2667    0.1644    0.2034       146
          21     0.3491    0.2534    0.2937       146
          22     0.4756    0.5342    0.5032       146
          23     0.2930    0.4315    0.3490       146

    accuracy                         0.4523      3504
   macro avg     0.4603    0.4523    0.4423      3504
weighted avg     0.4603    0.4523    0.4423      3504

